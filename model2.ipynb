{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, AveragePooling2D\n",
    "from keras import Sequential, optimizers\n",
    "from keras import backend as K\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import random\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"chestmnist.npz\")\n",
    "train_data = data[\"train_images\"]\n",
    "val_data = data[\"val_images\"]\n",
    "test_data = data[\"test_images\"]\n",
    "train_labels = data[\"train_labels\"]\n",
    "val_labels = data[\"val_labels\"]\n",
    "test_labels = data[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6,)\n",
      "(78468, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(data))\n",
    "print(np.shape(data[\"train_images\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(labels, class_num):\n",
    "    counts = np.zeros(class_num)\n",
    "    for label in labels:\n",
    "        for i in np.where(label != 0)[0]:\n",
    "            counts[i]+=1\n",
    "    # counts = [i/len(labels) for i in counts]\n",
    "\n",
    "    return counts\n",
    "\n",
    "def get_equal_indicies(labels, class_equal):\n",
    "    indicies = [i for i in range(np.shape(labels)[0]) if labels[i][class_equal] == 1]\n",
    "    return indicies\n",
    "\n",
    "def remove_class(data, labels, class_to_remove):\n",
    "    chosen_indicies = set(get_equal_indicies(labels, class_to_remove))\n",
    "    remaining_indicies = [i for i in range(np.shape(data)[0]) if i not in chosen_indicies]\n",
    "    data, labels = data[remaining_indicies], labels[remaining_indicies]\n",
    "    labels = np.delete(labels, (class_to_remove), axis=1)\n",
    "    return data, labels\n",
    "\n",
    "def add_no_class(labels):\n",
    "    to_append = np.array([np.array([1]) if (label == np.zeros(np.shape(label)[0])).all() else np.array([0]) for label in labels])\n",
    "    labels = np.append(labels, to_append, axis=1)\n",
    "    return labels\n",
    "\n",
    "class_num = np.shape(train_labels)[1]\n",
    "# print(np.shape(train_labels))\n",
    "train_counts = get_counts(train_labels, class_num+1)\n",
    "train_data, train_labels = remove_class(train_data, train_labels, class_num-1)\n",
    "train_counts = get_counts(train_labels, class_num)\n",
    "class_num-=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset, labels, class_num):\n",
    "    split_labels = []\n",
    "    split_data = []\n",
    "\n",
    "    for i in range(class_num):\n",
    "        split_data.append(copy.deepcopy(dataset))\n",
    "        to_add = [1 if label[i] == 1 else 0 for label in labels]\n",
    "        split_labels.append(to_add)\n",
    "        \n",
    "    return split_data, split_labels \n",
    "\n",
    "split_train_images, split_labels = split_data(train_data, train_labels, class_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140702, 784)\n",
      "(152752, 784)\n",
      "(138144, 784)\n",
      "(128864, 784)\n",
      "(148704, 784)\n",
      "(147910, 784)\n",
      "(154696, 784)\n",
      "(149252, 784)\n",
      "(150130, 784)\n",
      "(153274, 784)\n",
      "(153050, 784)\n",
      "(154340, 784)\n",
      "(152102, 784)\n"
     ]
    }
   ],
   "source": [
    "def shuffle_together(data, labels):\n",
    "    p = np.random.permutation(len(data))\n",
    "    return data[p], labels[p]\n",
    "\n",
    "# def subsample_class(data, labels, majority_class):\n",
    "#     all_indices = np.array(get_equal_indicies(labels, majority_class))\n",
    "\n",
    "#     excluded_indices = [all_indices[(random.randint(0,len(all_indices)-1))] for i in range(len(all_indices))]\n",
    "#     excluded_indicies = set(excluded_indices)\n",
    "#     chosen_indicies = np.array([i for i in range(np.shape(data)[0]) if i not in excluded_indicies])\n",
    "\n",
    "#     return data[chosen_indicies], labels[chosen_indicies]\n",
    "\n",
    "# def oversample_class(data, labels, minority_class, copy_num, class_num):\n",
    "#     all_indices = [i for i in get_equal_indicies(labels, minority_class) if list(labels[i]).count(1) == 1]\n",
    "#     data_to_add = np.zeros((copy_num, 28, 28))\n",
    "#     labels_to_add = np.zeros((copy_num, class_num), dtype=int)\n",
    "\n",
    "#     for i in range(copy_num):\n",
    "#         rnd_index = random.randint(0,len(all_indices)-1)\n",
    "#         data_to_add[i] = data[all_indices[rnd_index]].copy()\n",
    "#         labels_to_add[i] = labels[all_indices[rnd_index]].copy()\n",
    "\n",
    "#     # labels_to_add = np.reshape(labels_to_add, (np.shape(labels_to_add)[0]))\n",
    "#     data = np.append(data, data_to_add, axis=0)\n",
    "#     labels = np.append(labels, labels_to_add, axis=0)\n",
    "\n",
    "#     return data, labels\n",
    "\n",
    "# def oversample_binary(data, labels, copy_num):\n",
    "#     chosen_indicies = [i for i in range(np.shape(data)[0]) if labels[i] == 1]\n",
    "#     data_to_add = np.zeros((copy_num, 28, 28))\n",
    "\n",
    "#     for i in range(copy_num):\n",
    "#         rnd_index = random.randint(0,len(chosen_indicies)-1)\n",
    "#         data_to_add[i] = data[chosen_indicies[rnd_index]].copy()\n",
    "    \n",
    "#     data = np.append(data, data_to_add, axis=0)\n",
    "#     labels = np.append(labels, np.ones(copy_num))\n",
    "\n",
    "#     data, labels = shuffle_together(data, labels)\n",
    "#     return data, labels\n",
    "\n",
    "def balance_dataset(split_dataset, split_labels):\n",
    "    # initialise samplers\n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    rus = RandomUnderSampler(random_state=0)\n",
    "    \n",
    "    # iterate through each class to balance each dataset\n",
    "    for class_index in range(len(split_dataset)):\n",
    "        split_labels[class_index] = np.array(split_labels[class_index])\n",
    "\n",
    "        # reshape as over samplers require 2 dimensional arrays\n",
    "        split_dataset[class_index] = split_dataset[class_index].reshape((78324,784))\n",
    "\n",
    "        # oversample dataset\n",
    "        split_dataset[class_index], split_labels[class_index] = ros.fit_resample(split_dataset[class_index], split_labels[class_index])\n",
    "        print(np.shape(split_dataset[class_index]))\n",
    "        length = np.shape(split_dataset[class_index])[0]\n",
    "\n",
    "        # reshape back into 3 dimensional array\n",
    "        split_dataset[class_index] = split_dataset[class_index].reshape((length,28,28))\n",
    "\n",
    "        split_dataset[class_index], split_labels[class_index] = shuffle_together(split_dataset[class_index], split_labels[class_index])\n",
    "\n",
    "    return split_dataset, split_labels\n",
    "\n",
    "\n",
    "split_train_images, split_labels = balance_dataset(split_train_images, split_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Imbalanced-learn currently supports binary, multiclass and binarized encoded multiclasss targets. Multilabel and multioutput targets are not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m ros \u001b[38;5;241m=\u001b[39m RandomOverSampler(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m train_data \u001b[38;5;241m=\u001b[39m train_data\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m78324\u001b[39m,\u001b[38;5;241m784\u001b[39m))\n\u001b[0;32m---> 22\u001b[0m train_data, train_labels \u001b[38;5;241m=\u001b[39m \u001b[43mros\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(np\u001b[38;5;241m.\u001b[39mshape(train_data))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_resample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/base.py:106\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    104\u001b[0m check_classification_targets(y)\n\u001b[1;32m    105\u001b[0m arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m--> 106\u001b[0m X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy_ \u001b[38;5;241m=\u001b[39m check_sampling_strategy(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msampling_strategy, y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampling_type\n\u001b[1;32m    110\u001b[0m )\n\u001b[1;32m    112\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_resample(X, y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/over_sampling/_random_over_sampler.py:157\u001b[0m, in \u001b[0;36mRandomOverSampler._check_X_y\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_X_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m--> 157\u001b[0m     y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_target_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindicate_one_vs_all\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     X \u001b[38;5;241m=\u001b[39m _check_X(X)\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/imblearn/utils/_validation.py:156\u001b[0m, in \u001b[0;36mcheck_target_type\u001b[0;34m(y, indicate_one_vs_all)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m type_y \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-indicator\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39many(y\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 156\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    157\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mImbalanced-learn currently supports binary, multiclass and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    158\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinarized encoded multiclasss targets. Multilabel and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    159\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultioutput targets are not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         )\n\u001b[1;32m    161\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Imbalanced-learn currently supports binary, multiclass and binarized encoded multiclasss targets. Multilabel and multioutput targets are not supported."
     ]
    }
   ],
   "source": [
    "\n",
    "# def loss(target, output):\n",
    "#     weights = np.array([0.4999014531185609, 1.023027280727486, 0.43079488604780436, 0.2869071613672823, 1.0034527406128615, 0.9122715233953503, 1.0209309133489461, 1.077802673259677, 1.222986893437952, 1.181302396477263, 1.1077582784086397, 0.8634563010646199, 0.8767519326252279, 0.6890930646117368])\n",
    "#     target = tf.convert_to_tensor(target)\n",
    "#     output = tf.convert_to_tensor(output)\n",
    "#     target.shape.assert_is_compatible_with(output.shape)\n",
    "#     weights = tf.reshape(tf.convert_to_tensor(weights, dtype=target.dtype), (1,-1))\n",
    "\n",
    "#     # Adjust the predictions so that the probability of\n",
    "#     # each class for every sample adds up to 1\n",
    "#     # This is needed to ensure that the cross entropy is\n",
    "#     # computed correctly.\n",
    "#     output = output / tf.reduce_sum(output, -1, True)\n",
    "\n",
    "#     # Compute cross entropy from probabilities.\n",
    "#     epsilon_ = tf.constant(tf.keras.backend.epsilon(), output.dtype.base_dtype)\n",
    "#     output = tf.clip_by_value(output, epsilon_, 1.0 - epsilon_)\n",
    "#     return -tf.reduce_sum(weights * target * tf.math.log(output), axis=-1)\n",
    "\n",
    "# del data \n",
    "# ros = RandomOverSampler(random_state=0)\n",
    "# train_data = train_data.reshape((78324,784))\n",
    "# train_data, train_labels = ros.fit_resample(train_data, train_labels)\n",
    "# print(np.shape(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_models = [0]*class_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "2312/2312 [==============================] - 21s 8ms/step - loss: 0.7055 - auc: 0.5397 - accuracy: 0.5306\n",
      "Epoch 2/40\n",
      "2312/2312 [==============================] - 19s 8ms/step - loss: 0.6839 - auc: 0.5767 - accuracy: 0.5559\n",
      "Epoch 3/40\n",
      "2312/2312 [==============================] - 19s 8ms/step - loss: 0.6790 - auc: 0.5935 - accuracy: 0.5703\n",
      "Epoch 4/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6748 - auc: 0.6061 - accuracy: 0.5775\n",
      "Epoch 5/40\n",
      "2312/2312 [==============================] - 19s 8ms/step - loss: 0.6713 - auc: 0.6147 - accuracy: 0.5838\n",
      "Epoch 6/40\n",
      "2312/2312 [==============================] - 19s 8ms/step - loss: 0.6683 - auc: 0.6218 - accuracy: 0.5887\n",
      "Epoch 7/40\n",
      "2312/2312 [==============================] - 19s 8ms/step - loss: 0.6651 - auc: 0.6290 - accuracy: 0.5933\n",
      "Epoch 8/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6626 - auc: 0.6343 - accuracy: 0.5958\n",
      "Epoch 9/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6600 - auc: 0.6395 - accuracy: 0.6005\n",
      "Epoch 10/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6573 - auc: 0.6452 - accuracy: 0.6044\n",
      "Epoch 11/40\n",
      "2312/2312 [==============================] - 19s 8ms/step - loss: 0.6551 - auc: 0.6494 - accuracy: 0.6052\n",
      "Epoch 12/40\n",
      "2312/2312 [==============================] - 19s 8ms/step - loss: 0.6521 - auc: 0.6547 - accuracy: 0.6095\n",
      "Epoch 13/40\n",
      "2312/2312 [==============================] - 19s 8ms/step - loss: 0.6500 - auc: 0.6583 - accuracy: 0.6109\n",
      "Epoch 14/40\n",
      "2312/2312 [==============================] - 17s 7ms/step - loss: 0.6474 - auc: 0.6630 - accuracy: 0.6145\n",
      "Epoch 15/40\n",
      "2312/2312 [==============================] - 17s 7ms/step - loss: 0.6452 - auc: 0.6664 - accuracy: 0.6168\n",
      "Epoch 16/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6430 - auc: 0.6702 - accuracy: 0.6191\n",
      "Epoch 17/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6404 - auc: 0.6740 - accuracy: 0.6209\n",
      "Epoch 18/40\n",
      "2312/2312 [==============================] - 19s 8ms/step - loss: 0.6386 - auc: 0.6768 - accuracy: 0.6239\n",
      "Epoch 19/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6363 - auc: 0.6799 - accuracy: 0.6255\n",
      "Epoch 20/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6347 - auc: 0.6819 - accuracy: 0.6263\n",
      "Epoch 21/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6327 - auc: 0.6850 - accuracy: 0.6293\n",
      "Epoch 22/40\n",
      "2312/2312 [==============================] - 17s 7ms/step - loss: 0.6309 - auc: 0.6874 - accuracy: 0.6315\n",
      "Epoch 23/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6292 - auc: 0.6896 - accuracy: 0.6323\n",
      "Epoch 24/40\n",
      "2312/2312 [==============================] - 17s 7ms/step - loss: 0.6274 - auc: 0.6920 - accuracy: 0.6335\n",
      "Epoch 25/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6258 - auc: 0.6944 - accuracy: 0.6359\n",
      "Epoch 26/40\n",
      "2312/2312 [==============================] - 17s 7ms/step - loss: 0.6244 - auc: 0.6958 - accuracy: 0.6360\n",
      "Epoch 27/40\n",
      "2312/2312 [==============================] - 19s 8ms/step - loss: 0.6222 - auc: 0.6987 - accuracy: 0.6389\n",
      "Epoch 28/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6208 - auc: 0.7005 - accuracy: 0.6396\n",
      "Epoch 29/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6192 - auc: 0.7023 - accuracy: 0.6410\n",
      "Epoch 30/40\n",
      "2312/2312 [==============================] - 18s 8ms/step - loss: 0.6187 - auc: 0.7026 - accuracy: 0.6413\n",
      "Epoch 31/40\n",
      "1839/2312 [======================>.......] - ETA: 4s - loss: 0.6164 - auc: 0.7054 - accuracy: 0.6424"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train_data = train_data.astype('float32')\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcnn_models\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_train_images\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_labels\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# for i in range(class_num):\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#     print(\"Feature:\", i)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     cnn_models[i].fit(split_train_images[i], split_labels[i], batch_size=64, epochs=5)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m   _set_arg_keywords(concrete_function)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:226\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    216\u001b[0m   args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    217\u001b[0m       \u001b[38;5;241m*\u001b[39mtracing_options\u001b[38;5;241m.\u001b[39minput_signature,\n\u001b[1;32m    218\u001b[0m       \u001b[38;5;241m*\u001b[39margs[\u001b[38;5;28mlen\u001b[39m(tracing_options\u001b[38;5;241m.\u001b[39minput_signature) :],\n\u001b[1;32m    219\u001b[0m   )\n\u001b[1;32m    221\u001b[0m current_func_context \u001b[38;5;241m=\u001b[39m function_context\u001b[38;5;241m.\u001b[39mmake_function_context(\n\u001b[1;32m    222\u001b[0m     tracing_options\u001b[38;5;241m.\u001b[39mscope_type\n\u001b[1;32m    223\u001b[0m )\n\u001b[1;32m    225\u001b[0m capture_types \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 226\u001b[0m     \u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_captures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcapture_types\u001b[49m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_captures\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    229\u001b[0m )\n\u001b[1;32m    230\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    231\u001b[0m     function_type_utils\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    232\u001b[0m         args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    236\u001b[0m     )\n\u001b[1;32m    237\u001b[0m )\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/core/function/capture/capture_container.py:310\u001b[0m, in \u001b[0;36mFunctionCaptures.capture_types\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_by_val_capture_tuples\u001b[38;5;241m.\u001b[39mappend((external, internal))\n\u001b[1;32m    305\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_capture_types \u001b[38;5;241m=\u001b[39m py_collections\u001b[38;5;241m.\u001b[39mOrderedDict(\n\u001b[1;32m    306\u001b[0m       \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_by_val_tracetype\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    307\u001b[0m       \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_by_ref_tracetype\u001b[38;5;241m.\u001b[39mitems())\n\u001b[1;32m    308\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcapture_types\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    312\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_by_val_internal\u001b[38;5;241m.\u001b[39mmutated \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_by_val_external\u001b[38;5;241m.\u001b[39mmutated:\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recompute_cached_properties()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train_data = train_data.astype('float32')\n",
    "cnn_models[5].fit(split_train_images[5], split_labels[5], batch_size=64, epochs=40)\n",
    "# for i in range(class_num):\n",
    "#     print(\"Feature:\", i)\n",
    "#     cnn_models[i].fit(split_train_images[i], split_labels[i], batch_size=64, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
