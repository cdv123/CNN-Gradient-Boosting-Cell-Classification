{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, AveragePooling2D\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from sklearn.utils import class_weight\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"dermamnist.npz\")\n",
    "train_data = data[\"train_images\"]\n",
    "val_data = data[\"val_images\"]\n",
    "test_data = data[\"test_images\"]\n",
    "train_labels = data[\"train_labels\"]\n",
    "val_labels = data[\"val_labels\"]\n",
    "test_labels = data[\"test_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(labels, class_num):\n",
    "    counts = np.zeros(class_num)\n",
    "    for label in labels:\n",
    "        counts[label]+=1\n",
    "    \n",
    "    counts = [i/len(labels) for i in counts]\n",
    "\n",
    "    return counts\n",
    "\n",
    "train_counts = get_counts(train_labels, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.03253888968174683, 0.051234479805908374, 0.10974739546168118, 0.01141715427429713, 0.11117453974596832, 0.6697588126159555, 0.0141287284144427]\n",
      "(7007, 1)\n",
      "769\n",
      "(7007, 1) (769, 1)\n",
      "[[5]\n",
      " [4]\n",
      " [2]\n",
      " [2]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [0]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [1]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [2]\n",
      " [4]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [0]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [6]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [0]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [2]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [5]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [6]\n",
      " [2]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [1]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [1]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [0]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [2]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [0]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [0]\n",
      " [5]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [0]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [0]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [1]\n",
      " [0]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [2]\n",
      " [4]\n",
      " [1]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [4]\n",
      " [5]\n",
      " [0]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [1]\n",
      " [0]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [2]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [4]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [0]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [0]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [6]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [1]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [0]\n",
      " [4]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [4]\n",
      " [1]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [5]\n",
      " [4]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [0]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [4]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [2]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [3]\n",
      " [5]\n",
      " [2]\n",
      " [0]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [0]\n",
      " [2]\n",
      " [2]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [0]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [2]\n",
      " [4]\n",
      " [2]\n",
      " [3]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [2]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [4]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [5]\n",
      " [4]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]\n",
      " [6]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [2]\n",
      " [5]\n",
      " [5]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [4]\n",
      " [5]\n",
      " [1]\n",
      " [5]\n",
      " [5]]\n",
      "(7776, 1)\n",
      "[0.03189300411522634, 0.051826131687242795, 0.10943930041152264, 0.010673868312757202, 0.11381172839506173, 0.6678240740740741, 0.014531893004115226]\n"
     ]
    }
   ],
   "source": [
    "def shuffle_together(data, labels):\n",
    "    p = np.random.permutation(len(data))\n",
    "    return data[p], labels[p]\n",
    "\n",
    "def oversample_class(data, labels, minority_class):\n",
    "\n",
    "    all_indices = np.where(labels == minority_class)[0]\n",
    "    data_to_add = np.zeros((len(all_indices), 28, 28, 3))\n",
    "    print(len(all_indices))\n",
    "    labels_to_add = np.zeros((len(all_indices), 1), dtype=int)\n",
    "    print(np.shape(labels), np.shape(labels_to_add))\n",
    "\n",
    "    for i in range(len(all_indices)):\n",
    "        rnd_index = random.randint(0,len(all_indices)-1)\n",
    "        data_to_add[i] = data[rnd_index].copy()\n",
    "        labels_to_add[i] = labels[rnd_index].copy()\n",
    "\n",
    "    data = np.append(data, data_to_add, axis=0)\n",
    "    print(labels_to_add)\n",
    "    labels = np.append(labels, labels_to_add, axis=0)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "# print(train_data)\n",
    "print(get_counts(train_labels, 7))\n",
    "print(np.shape(train_labels))\n",
    "train_data, train_labels = oversample_class(train_data, train_labels, 2)\n",
    "print(np.shape(train_labels))\n",
    "train_data, train_labels = shuffle_together(train_data, train_labels)\n",
    "print(get_counts(train_labels, 7))\n",
    "# y = train_data[0].copy()\n",
    "# print(y)\n",
    "# print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels, class_num):\n",
    "    one_hot_labels = np.zeros((np.shape(labels)[0], class_num), dtype=int)\n",
    "    for i, label in enumerate(labels):\n",
    "        one_hot_labels[i][int(label[0])] = 1\n",
    "    \n",
    "    return one_hot_labels\n",
    "\n",
    "train_labels = one_hot_encode(train_labels, 7)\n",
    "val_labels = one_hot_encode(val_labels, 7)\n",
    "test_labels = one_hot_encode(test_labels, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_num = 7\n",
    "# class_weights = {}\n",
    "# for i in range(class_num):\n",
    "#     class_weights[i] = np.max(train_counts)/train_counts[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.regularizers.l2(0.02)\n",
    "cnn_model = Sequential()\n",
    "cnn_model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape= (28, 28, 3)))\n",
    "cnn_model.add(MaxPooling2D(2, 2))\n",
    "# cnn_model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape= (28, 28, 3)))\n",
    "# cnn_model.add(MaxPooling2D(2, 2))\n",
    "cnn_model.add(Dropout(.1))\n",
    "cnn_model.add(Flatten())\n",
    "cnn_model.add(Dense(20, activation='relu'))\n",
    "cnn_model.add(Dense(7, activation='softmax'))\n",
    "cnn_model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "219/219 [==============================] - 5s 9ms/step - loss: 3.0576 - accuracy: 0.6441\n",
      "Epoch 2/10\n",
      "219/219 [==============================] - 2s 10ms/step - loss: 1.6702 - accuracy: 0.6698\n",
      "Epoch 3/10\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 1.5205 - accuracy: 0.6698\n",
      "Epoch 4/10\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 1.4051 - accuracy: 0.6698\n",
      "Epoch 5/10\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 1.4915 - accuracy: 0.6673\n",
      "Epoch 6/10\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 1.2615 - accuracy: 0.6698\n",
      "Epoch 7/10\n",
      "219/219 [==============================] - 2s 7ms/step - loss: 1.2210 - accuracy: 0.6698\n",
      "Epoch 8/10\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 1.1936 - accuracy: 0.6698\n",
      "Epoch 9/10\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 1.1751 - accuracy: 0.6698\n",
      "Epoch 10/10\n",
      "219/219 [==============================] - 2s 8ms/step - loss: 1.1625 - accuracy: 0.6698\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 1.1600 - accuracy: 0.6690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1599526405334473, 0.6689929962158203]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn_model.fit(train_data, train_labels, batch_size=32, epochs=10)\n",
    "results = cnn_model.predict(val_data)\n",
    "cnn_model.evaluate(val_data, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.04463231 0.05623441 0.10444973 0.03916988 0.10504017 0.6139832\n",
      " 0.03649038]\n",
      "[0.04463231 0.05623441 0.10444973 0.03916988 0.10504017 0.6139832\n",
      " 0.03649038]\n",
      "[0.04463231 0.05623441 0.10444973 0.03916988 0.10504017 0.6139832\n",
      " 0.03649038]\n",
      "[0.04463231 0.05623441 0.10444973 0.03916988 0.10504017 0.6139832\n",
      " 0.03649038]\n",
      "[0.04463231 0.05623441 0.10444973 0.03916988 0.10504017 0.6139832\n",
      " 0.03649038]\n"
     ]
    }
   ],
   "source": [
    "print(results[1])\n",
    "print(results[2])\n",
    "print(results[3])\n",
    "print(results[4])\n",
    "print(results[5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
